{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNT3gDKutLBwFqaje0MownK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICSg7VqJxyWa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTYFZ6Oex19O",
        "outputId": "8fe88d78-0bee-4c4a-8557-70dc6dcee06d"
      },
      "source": [
        "model = nn.Linear(4, 1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=4, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EuCbqgYx_tX",
        "outputId": "bfbc5fae-2235-4b6e-a830-4fe4501d8db2"
      },
      "source": [
        "state_dict = model.state_dict()\n",
        "state_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([[ 0.0555,  0.2672, -0.2744,  0.3406]])),\n",
              "             ('bias', tensor([0.3496]))])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm4v4v25y-b2",
        "outputId": "739d3c21-12a3-40c4-904c-b7c056ba06c9"
      },
      "source": [
        "weights = state_dict['weight']\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0555,  0.2672, -0.2744,  0.3406]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmuK_AYzzKt8",
        "outputId": "cec72487-f8cc-4caf-fcb3-1f09ef9324de"
      },
      "source": [
        "bias = state_dict['bias']\n",
        "bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3496])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rStpkqYy2yDM",
        "outputId": "62ac0c4b-0f55-4a7b-fd99-a35d5665b91b"
      },
      "source": [
        "loss_func = nn.MSELoss()\n",
        "loss_func"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MSELoss()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ9SnFNi2323",
        "outputId": "69ba7b6e-380e-467d-bd00-ac5ae7e02157"
      },
      "source": [
        "x = torch.rand(4)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2155, 0.9721, 0.2278, 0.6490])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeEmZk6b2-EV",
        "outputId": "6a661054-608b-4e06-bb08-8a9df9d1a2f2"
      },
      "source": [
        "y = model(x)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7798], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xddTEiu3BUo",
        "outputId": "4669b578-3517-4ad8-ce03-9e36c1dbb666"
      },
      "source": [
        "target = y.clone().detach() * 5 + 1.1\n",
        "y = torch.tensor(y, requires_grad=True)\n",
        "loss = loss_func(y, target)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.8010, grad_fn=<MseLossBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK4xXbPy8ta4",
        "outputId": "3f199e6b-1922-4e8c-c4e4-612f37a0060e"
      },
      "source": [
        "print(weights.grad, weights.is_leaf)\n",
        "print(bias.grad, bias.is_leaf)\n",
        "print(loss.grad, loss.is_leaf)\n",
        "print(y.grad, y.is_leaf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None True\n",
            "None True\n",
            "None False\n",
            "None True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9gt2_hx5_jP"
      },
      "source": [
        "loss.backward(retain_graph=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwFih7ed8O6N",
        "outputId": "049e2dd5-b4c9-487c-ec90-90d9bf62217d"
      },
      "source": [
        "print(weights.grad, weights.is_leaf)\n",
        "print(bias.grad, bias.is_leaf)\n",
        "print(loss.grad, loss.is_leaf)\n",
        "print(y.grad, y.is_leaf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None True\n",
            "None True\n",
            "None False\n",
            "tensor([-8.4382]) True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVpbuGxG7J4H",
        "outputId": "ed5f5e37-e1eb-4cf6-a011-63483689daad"
      },
      "source": [
        "state_dict = model.state_dict()\n",
        "print(state_dict)\n",
        "print(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[ 0.0555,  0.2672, -0.2744,  0.3406]])), ('bias', tensor([0.3496]))])\n",
            "<generator object Module.parameters at 0x7fe25cc30c50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8brdH8yN7RBK"
      },
      "source": [
        "optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyGo1Oeb7dfg",
        "outputId": "f4c2234c-97b8-42be-d30d-3cfa68ad05cc"
      },
      "source": [
        "state_dict = model.state_dict()\n",
        "print(state_dict)\n",
        "print(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[ 0.0555,  0.2672, -0.2744,  0.3406]])), ('bias', tensor([0.3496]))])\n",
            "<generator object Module.parameters at 0x7fe25cc30a50>\n"
          ]
        }
      ]
    }
  ]
}